#!/usr/bin/env python
"""Test NIXL GDS Loader"""

import sys
import argparse
import torch
from pathlib import Path

# Add project to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.loaders import NIXLGDSLoader

def main():
    parser = argparse.ArgumentParser(description="Test NIXL GDS Loader")
    parser.add_argument(
        "--model",
        type=str,
        default="7b",
        choices=["0.6b", "7b"],
        help="Model size: 0.6b or 7b (default: 0.6b)"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda:0",
        help="Device (default: cuda:0)"
    )
    args = parser.parse_args()

    # Map model choice to path
    model_paths = {
        "0.6b": "./models/qwen3-0.6b",
        "7b": "./models/qwen2.5-7b"
    }
    model_path = model_paths[args.model]
    device = args.device

    print("\n" + "="*70)
    print("æµ‹è¯• NIXL GDS Loader")
    print("="*70)
    print(f"æ¨¡å‹å¤§å°: {args.model}")
    print(f"æ¨¡å‹è·¯å¾„: {model_path}")
    print(f"è®¾å¤‡: {device}")
    print("="*70)

    # æ£€æŸ¥æ¨¡å‹è·¯å¾„
    if not Path(model_path).exists():
        print(f"âœ— æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
        print("  è¯·å…ˆè¿è¡Œ: python scripts/download_model.py")
        return 1
    
    print(f"âœ“ æ¨¡å‹è·¯å¾„: {model_path}")
    
    # åˆå§‹åŒ– Loader
    print("\nåˆå§‹åŒ– NIXL GDS Loader...")
    try:
        loader = NIXLGDSLoader(model_path, device=device)
        print(f"âœ“ Loader åˆå§‹åŒ–æˆåŠŸ")
        print(f"  NIXL çŠ¶æ€: {'å¯ç”¨' if loader.nixl_available else 'ä¸å¯ç”¨ï¼ˆå°†ä½¿ç”¨å›é€€ï¼‰'}")
    except Exception as e:
        print(f"âœ— Loader åˆå§‹åŒ–å¤±è´¥: {e}")
        return 1
    
    # åŠ è½½æ¨¡å‹
    print("\nå¼€å§‹åŠ è½½æ¨¡å‹...")
    try:
        model = loader.load_model(torch_dtype=torch.bfloat16)
        print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    # è¾“å‡ºç»Ÿè®¡
    print(f"\n{'='*70}")
    print("ã€æ€§èƒ½ç»Ÿè®¡ - è®°å½•è¿™äº›æ•°æ®ã€‘")
    print(f"{'='*70}")
    print(f"âœ“ åŠ è½½æ—¶é—´: {loader.load_stats['model_load_time']:.4f} ç§’")
    print(f"âœ“ GPU å†…å­˜: {loader.load_stats['gpu_memory_mb']:.2f} MB")
    print(f"âœ“ CPU å†…å­˜: {loader.load_stats['cpu_memory_mb']:.2f} MB")
    print(f"âœ“ NIXL çŠ¶æ€: {'å¯ç”¨' if loader.nixl_available else 'å›é€€æ¨¡å¼'}")
    
    # è·å–æ¨¡å‹ä¿¡æ¯
    info = loader.get_model_info()
    print(f"\næ¨¡å‹ä¿¡æ¯:")
    print(f"  å‚æ•°é‡: {info['num_parameters']:,}")
    print(f"  å‚æ•°å¤§å°: {info['param_size_mb']:.2f} MB")
    print(f"{'='*70}")
    
    # æµ‹è¯•æ¨ç†
    print("\næµ‹è¯•æ¨ç†...")
    try:
        output = loader.test_inference(
            prompt="Hello, how are you?",
            max_new_tokens=20
        )
        print("âœ“ æ¨ç†æˆåŠŸ")
    except Exception as e:
        print(f"âœ— æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    print("\n" + "="*70)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("="*70 + "\n")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
